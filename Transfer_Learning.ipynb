{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg16\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, InputLayer\n",
    "import keras\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('dogs-vs-cats/train/*')\n",
    "\n",
    "cat_files = [fn for fn in files if 'cat' in fn]\n",
    "dog_files = [fn for fn in files if 'dog' in fn]\n",
    "len(cat_files), len(dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat datasets: (1500,) (500,) (500,)\n",
      "Dog datasets: (1500,) (500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "cat_train = np.random.choice(cat_files, size=1500, replace=False)\n",
    "dog_train = np.random.choice(dog_files, size=1500, replace=False)\n",
    "cat_files = list(set(cat_files) - set(cat_train))\n",
    "dog_files = list(set(dog_files) - set(dog_train))\n",
    "\n",
    "cat_val = np.random.choice(cat_files, size=500, replace=False)\n",
    "dog_val = np.random.choice(dog_files, size=500, replace=False)\n",
    "cat_files = list(set(cat_files) - set(cat_val))\n",
    "dog_files = list(set(dog_files) - set(dog_val))\n",
    "\n",
    "cat_test = np.random.choice(cat_files, size=500, replace=False)\n",
    "dog_test = np.random.choice(dog_files, size=500, replace=False)\n",
    "\n",
    "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape)\n",
    "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'training_data'\n",
    "val_dir = 'validation_data'\n",
    "test_dir = 'test_data'\n",
    "\n",
    "train_files = np.concatenate([cat_train, dog_train])\n",
    "validate_files = np.concatenate([cat_val, dog_val])\n",
    "test_files = np.concatenate([cat_test, dog_test])\n",
    "\n",
    "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\n",
    "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None\n",
    "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None\n",
    "\n",
    "for fn in train_files:\n",
    "    shutil.copy(fn, train_dir)\n",
    "\n",
    "for fn in validate_files:\n",
    "    shutil.copy(fn, val_dir)\n",
    "    \n",
    "for fn in test_files:\n",
    "    shutil.copy(fn, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (2918, 150, 150, 3) \tValidation dataset shape: (992, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "IMG_DIM = (150, 150)\n",
    "\n",
    "train_files = glob.glob('training_data/*')\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in train_files]\n",
    "\n",
    "validation_files = glob.glob('validation_data/*')\n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
    "validation_imgs = np.array(validation_imgs)\n",
    "validation_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in validation_files]\n",
    "\n",
    "print('Train dataset shape:', train_imgs.shape, '\\tValidation dataset shape:', validation_imgs.shape)\n",
    "\n",
    "train_imgs_scaled = train_imgs.astype('float32')\n",
    "validation_imgs_scaled  = validation_imgs.astype('float32')\n",
    "train_imgs_scaled /= 255\n",
    "validation_imgs_scaled /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog'] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "validation_labels_enc = le.transform(validation_labels)\n",
    "\n",
    "print(train_labels[1430:1450],train_labels_enc[1430:1450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saumitrd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saumitrd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x0000019A07E924E0> input_1 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A07AB8CF8> block1_conv1 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A07AFABE0> block1_conv2 False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000019A69821A20> block1_pool False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A698357F0> block2_conv1 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A6983AFD0> block2_conv2 False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000019A6983DD68> block2_pool False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A698449E8> block3_conv1 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A698514A8> block3_conv2 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A69851390> block3_conv3 False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000019A6985D978> block3_pool False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A69864A58> block4_conv1 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A69870278> block4_conv2 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A69875F98> block4_conv3 False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000019A69876B38> block4_pool False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A698837B8> block5_conv1 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A69888400> block5_conv2 False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000019A6989CBA8> block5_conv3 False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000019A6989C748> block5_pool False\n",
      "<keras.layers.core.Flatten object at 0x0000019A698A0198> flatten_1 False\n"
     ]
    }
   ],
   "source": [
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "vgg_model.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    print(layer, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottleneck_features(model, input_imgs):\n",
    "    features = model.predict(input_imgs, verbose=0)\n",
    "    return features\n",
    "    \n",
    "train_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)\n",
    "validation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Bottleneck Features:', train_features_vgg.shape, \n",
    "      '\\tValidation Bottleneck Features:', validation_features_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = vgg_model.output_shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(input_shape,)))\n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 30\n",
    "model.fit(x=train_features_vgg, y=train_labels_enc, validation_data=(validation_features_vgg, validation_labels_enc),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "model.save('cats_vs_dogs_transfer_learning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
